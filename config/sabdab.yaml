---

# wandb settings
project_name: flow_matching
model_name: all_atom_de_novo

# shared settings
shared:
    design_mode: &design_mode ["sequence", "backbone", "sidechain"]
    seed: &seed 2025

# training settings
trainer:
    devices: 1
    max_epochs: 200
    precision: 32-true # Use 32-bit precision as 16-bit causes instability in rotation flow
    gradient_clip_val: 1.0
    val_check_interval: 0.2
    accumulate_grad_batches: 4
    log_every_n_steps: 100
checkpoint:
    path: null
    load_optimizer: False

# abflow datamodule settings
datamodule:
    num_workers: 8
    batch_size: 8
    redesign:
        framework: False
        hcdr1: False
        hcdr2: False
        hcdr3: True
        lcdr1: True
        lcdr2: False
        lcdr3: False
    max_crop_size: 180
    antigen_crop_size: 60
    dataset:
        name: sabdab
        seed: *seed
        num_val_cluster: 10
        paths:
            data: /scratch/hz362/datavol/data/
            model: /scratch/hz362/datavol/model/

# abflow model settings
model:
    loss_weighting:
        sequence_vf_loss: 100.0
        translation_vf_loss: 1.0
        rotation_vf_loss: 10.0
        dihedral_vf_loss: 10.0
        distogram_loss: 1.0
        confidence_lddt_loss: 1.0
        confidence_de_loss: 1.0
        confidence_ae_loss: 1.0
    learning_rate: 0.0001
    design_mode: *design_mode
    seed: *seed

# abflow network settings
network:
    design_mode: *design_mode
    c_s: 192 # default: 384
    c_z: 64 # default: 128
    n_condition_module_blocks: 8 # default: 48
    n_denoising_module_blocks: 4 # default: 24
    n_confidence_module_blocks: 1 # default: 4
    n_cycle: 4
    mini_rollout_steps: 20
    full_rollout_steps: 100
    label_smoothing: 0.0
    max_time_clamp: 0.99
    network_params:
        Pairformer:
            dropout_rowwise_probabilty: 0.25
            dropout_columnwise_probabilty: 0.25
            TriangleAttentionStartingNode:
                n_head: 4
            TriangleAttentionEndingNode:
                n_head: 4
            AttentionPairBias:
                n_head: 6
        InvariantPointAttention:
            dropout_probability: 0.1
            n_head: 6
            n_query_points: 4
            n_point_values: 8