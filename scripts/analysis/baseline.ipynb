{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### diffab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "\n",
    "pdb_dir = \"/spinning1/sharedby/hz362/AbFlow/data/rabd/pdb/\"\n",
    "diffab_repo_dir = \"/spinning1/sharedby/hz362/AbFlow/benchmarks/diffab/\"\n",
    "config_files = [\n",
    "    \"configs/test/codesign_single.yml\",\n",
    "    \"configs/test/fixbb.yml\",\n",
    "]\n",
    "results_dirs = [\n",
    "    \"results/codesign_single/\",\n",
    "    \"results/fixbb/\",\n",
    "]\n",
    "\n",
    "\n",
    "original_pdb_files = {f for f in os.listdir(pdb_dir) if f.endswith(\".pdb\")}\n",
    "original_working_dir = os.getcwd()\n",
    "\n",
    "try:\n",
    "    os.chdir(diffab_repo_dir)\n",
    "\n",
    "    for pdb_file in original_pdb_files:\n",
    "        pdb_file_path = os.path.join(original_working_dir, pdb_dir, pdb_file)\n",
    "\n",
    "        for config_file, results_dir in zip(config_files, results_dirs):\n",
    "\n",
    "            # check if the results directory exists\n",
    "            if not os.path.exists(results_dir):\n",
    "                os.makedirs(results_dir)\n",
    "\n",
    "            result_file_names = {f.split(\".\")[0] for f in os.listdir(results_dir)}\n",
    "            pdb_file_name = pdb_file.split(\".\")[0]\n",
    "\n",
    "            if pdb_file_name in result_file_names:\n",
    "                print(\n",
    "                    f\"Skipping {pdb_file}.pdb as it is already processed in {results_dir}\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            command = [\n",
    "                \"python\",\n",
    "                \"design_pdb.py\",\n",
    "                pdb_file_path,\n",
    "                \"--config\",\n",
    "                config_file,\n",
    "            ]\n",
    "\n",
    "            print(f\"Running command: {' '.join(command)}\")\n",
    "            subprocess.run(command, check=True)\n",
    "\n",
    "finally:\n",
    "    os.chdir(original_working_dir)\n",
    "\n",
    "    current_pdb_files = {f for f in os.listdir(pdb_dir) if f.endswith(\".pdb\")}\n",
    "    additional_files = current_pdb_files - original_pdb_files\n",
    "\n",
    "    for additional_file in additional_files:\n",
    "        os.remove(os.path.join(pdb_dir, additional_file))\n",
    "\n",
    "    print(\"Finished processing all PDB files. Additional files have been removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up diffab folders\n",
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "\n",
    "BASE_DIR = '/spinning1/sharedby/hz362/AbFlow/data/baseline/diffab'\n",
    "MODES = ['SG', 'DN']\n",
    "\n",
    "for mode in MODES:\n",
    "    mode_dir = os.path.join(BASE_DIR, mode)\n",
    "    for full_case_path in os.listdir(mode_dir):\n",
    "        case_path = os.path.join(mode_dir, full_case_path)\n",
    "\n",
    "        if not os.path.isdir(case_path):\n",
    "            continue\n",
    "\n",
    "        if \".pdb_\" not in full_case_path:\n",
    "            print(f\"Skipping invalid folder: {full_case_path}\")\n",
    "            continue\n",
    "        clean_name = full_case_path.split('.pdb_')[0]\n",
    "        new_case_path = os.path.join(mode_dir, clean_name)\n",
    "\n",
    "        if os.path.exists(new_case_path):\n",
    "            print(f\"Target folder already exists: {new_case_path}, skipping...\")\n",
    "            continue\n",
    "\n",
    "        h_cdr3_path = os.path.join(case_path, 'H_CDR3')\n",
    "        if not os.path.exists(h_cdr3_path):\n",
    "            print(f\"No H_CDR3 found in: {case_path}, skipping...\")\n",
    "            continue\n",
    "\n",
    "        os.makedirs(new_case_path)\n",
    "\n",
    "        pdb_files = sorted(glob(os.path.join(h_cdr3_path, '[0-9][0-9][0-9][0-9]*.pdb')))\n",
    "        for i, pdb_path in enumerate(pdb_files):\n",
    "            new_name = f'design_{i}.pdb'\n",
    "            shutil.copy2(pdb_path, os.path.join(new_case_path, new_name))\n",
    "\n",
    "        print(f\"‚úì Cleaned {full_case_path} ‚Üí {clean_name}\")\n",
    "\n",
    "print(\"Done cleaning baseline diffab folders.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "BASE_DIR = '/spinning1/sharedby/hz362/AbFlow/data/baseline/diffab'\n",
    "MODES = ['SG', 'DN']\n",
    "\n",
    "for mode in MODES:\n",
    "    mode_dir = os.path.join(BASE_DIR, mode)\n",
    "    for full_case_path in os.listdir(mode_dir):\n",
    "        case_path = os.path.join(mode_dir, full_case_path)\n",
    "\n",
    "        if not os.path.isdir(case_path):\n",
    "            continue\n",
    "\n",
    "        # Only remove timestamped folders\n",
    "        if \".pdb_\" not in full_case_path:\n",
    "            continue\n",
    "\n",
    "        clean_name = full_case_path.split(\".pdb_\")[0]\n",
    "        cleaned_path = os.path.join(mode_dir, clean_name)\n",
    "\n",
    "        if os.path.exists(cleaned_path):\n",
    "            print(f\"üóë Removing old folder: {case_path}\")\n",
    "            shutil.rmtree(case_path)\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Clean folder missing for: {clean_name}, skipping deletion\")\n",
    "\n",
    "print(\"Old timestamped folders cleaned up.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# === Paths ===\n",
    "input_dir = \"/spinning1/sharedby/hz362/AbFlow/data/rabd/pdb\"\n",
    "output_dir = \"/spinning1/sharedby/hz362/AbFlow/data/rabd/pdb_imgt\"\n",
    "immunopdb_script = \"/spinning1/sharedby/hz362/AbFlow/benchmarks/MEAN/data/ImmunoPDB.py\"\n",
    "\n",
    "# === Create output dir if needed ===\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# === Loop through .pdb files ===\n",
    "pdb_files = [f for f in os.listdir(input_dir) if f.endswith(\".pdb\")]\n",
    "\n",
    "for fname in pdb_files:\n",
    "    in_file = os.path.join(input_dir, fname)\n",
    "    out_file = os.path.join(output_dir, fname)  # keep same filename\n",
    "    cmd = [\n",
    "        \"python\", immunopdb_script,\n",
    "        \"-i\", in_file,\n",
    "        \"-o\", out_file,\n",
    "        \"-s\", \"imgt\"\n",
    "    ]\n",
    "    try:\n",
    "        subprocess.run(cmd, check=True)\n",
    "        print(f\"‚úÖ Renumbered {fname} ‚Üí pdb_imgt/\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"‚ùå Failed to renumber {fname}: {e}\")\n",
    "\n",
    "print(\"üéâ All PDBs processed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### abx (move this notebook to the abx folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from subprocess import run\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "pdb_input_dir = \"/spinning1/sharedby/hz362/AbFlow/data/rabd/pdb\"  # üîÅ Change this to your PDB input folder\n",
    "output_base_dir = \"/spinning1/sharedby/hz362/AbFlow/benchmarks/AbX/output/abx_hcdr3_design\"\n",
    "model_ckpt = \"/spinning1/sharedby/hz362/AbFlow/benchmarks/AbX/trained_model/abx_diffab.ckpt\"\n",
    "model_features = \"/spinning1/sharedby/hz362/AbFlow/benchmarks/AbX/config/config_data_feature.json\"\n",
    "model_config = \"/spinning1/sharedby/hz362/AbFlow/benchmarks/AbX/config/config_model.json\"\n",
    "\n",
    "# Make sure output directory exists\n",
    "os.makedirs(output_base_dir, exist_ok=True)\n",
    "\n",
    "# === Function to run design for each PDB ===\n",
    "def redesign_hcdr3(pdb_file, output_dir):\n",
    "    print(f\"üß¨ Designing HCDR3 for {os.path.basename(pdb_file)} ...\")\n",
    "    run([\n",
    "        \"python\", \"/spinning1/sharedby/hz362/AbFlow/benchmarks/AbX/design.py\",\n",
    "        \"--model\", model_ckpt,\n",
    "        \"--model_features\", model_features,\n",
    "        \"--model_config\", model_config,\n",
    "        \"--batch_size\", \"1\",\n",
    "        \"--num_samples\", \"1\",  # Adjust for more candidates\n",
    "        \"--pdb_file\", pdb_file,\n",
    "        \"--output_dir\", output_dir,\n",
    "        \"--mode\", \"design\"\n",
    "    ])\n",
    "\n",
    "# === Batch Process All PDBs ===\n",
    "pdb_files = sorted(glob.glob(os.path.join(pdb_input_dir, \"*.pdb\")))\n",
    "\n",
    "for pdb_path in pdb_files:\n",
    "    pdb_name = os.path.basename(pdb_path).replace(\".pdb\", \"\")\n",
    "    out_dir = os.path.join(output_base_dir, pdb_name)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    redesign_hcdr3(pdb_path, out_dir)\n",
    "\n",
    "print(\"‚úÖ Finished redesigning all PDBs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Paths\n",
    "input_root = \"/spinning1/sharedby/hz362/AbFlow/benchmarks/AbX/output/abx_hcdr3_design\"\n",
    "output_dir = \"/spinning1/sharedby/hz362/AbFlow/benchmarks/AbX/output/abx\"\n",
    "\n",
    "# Create output directory if not exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Go through all entries in the input directory\n",
    "for entry in os.listdir(input_root):\n",
    "    subdir = os.path.join(input_root, entry, \"design\", \"0000\")\n",
    "    if os.path.isdir(subdir):\n",
    "        pdb_files = [f for f in os.listdir(subdir) if f.endswith(\".pdb\")]\n",
    "        if pdb_files:\n",
    "            pdb_path = os.path.join(subdir, pdb_files[0])\n",
    "            output_path = os.path.join(output_dir, f\"{entry}.pdb\")\n",
    "            shutil.copy(pdb_path, output_path)\n",
    "            print(f\"‚úÖ Saved: {output_path}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è No PDB found in: {subdir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dymean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from Bio.PDB import PDBParser, PPBuilder\n",
    "\n",
    "# ‚úÖ Add dyMEAN to Python path\n",
    "sys.path.append(\"/spinning1/sharedby/hz362/AbFlow/benchmarks/dyMEAN\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/spinning1/sharedby/hz362/AbFlow/benchmarks\")  # üëà not just dyMEAN\n",
    "\n",
    "from api.design import design\n",
    "from api.binding_interface import get_interface\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from Bio.PDB import PDBParser, PPBuilder\n",
    "from anarci import number\n",
    "from api.design import design\n",
    "from api.binding_interface import get_interface\n",
    "\n",
    "\n",
    "def extract_chains_from_filename(pdb_filename):\n",
    "    \"\"\"\n",
    "    Extract heavy, light, and antigen chains from filenames like 4dtg_H_L_K.pdb\n",
    "    \"\"\"\n",
    "    name_parts = pdb_filename.stem.split(\"_\")\n",
    "    if len(name_parts) < 4:\n",
    "        raise ValueError(f\"Unexpected PDB filename format: {pdb_filename}\")\n",
    "    return name_parts[1], name_parts[2], name_parts[3]  # H, L, Ag\n",
    "\n",
    "\n",
    "\n",
    "def extract_sequences(pdb_path, heavy_chain, light_chain):\n",
    "    \"\"\"Extract heavy and light chain sequences from PDB\"\"\"\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure(\"pdb\", pdb_path)\n",
    "    ppb = PPBuilder()\n",
    "\n",
    "    heavy_seq = \"\"\n",
    "    light_seq = \"\"\n",
    "\n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            seq = \"\"\n",
    "            for pp in ppb.build_peptides(chain):\n",
    "                seq += pp.get_sequence()\n",
    "            if chain.id == heavy_chain:\n",
    "                heavy_seq = seq\n",
    "            elif chain.id == light_chain:\n",
    "                light_seq = seq\n",
    "\n",
    "    return str(heavy_seq), str(light_seq)\n",
    "\n",
    "\n",
    "def get_imgt_regions(sequence):\n",
    "    \"\"\"Split sequence into IMGT regions and return them\"\"\"\n",
    "    numbering, _ = number(sequence, scheme=\"imgt\")\n",
    "    non_gap_seq = [aa for (_, _), aa in numbering if aa != \"-\"]\n",
    "    non_gap_numbers = [number for (number, _), aa in numbering if aa != \"-\"]\n",
    "\n",
    "    ptr = [27, 39, 55, 66, 105, 118]\n",
    "    indices = [i for i, n in enumerate(non_gap_numbers) if n in ptr]\n",
    "    split_points = [0] + indices + [len(non_gap_seq)]\n",
    "    regions = [non_gap_seq[split_points[i]:split_points[i + 1]] for i in range(len(split_points) - 1)]\n",
    "\n",
    "    while len(regions) < 7:\n",
    "        regions.append([])\n",
    "\n",
    "    return [\"\".join(region) for region in regions]\n",
    "\n",
    "\n",
    "def get_frameworks(heavy_seq, light_seq):\n",
    "    h_regions = get_imgt_regions(heavy_seq)\n",
    "    l_regions = get_imgt_regions(light_seq)\n",
    "\n",
    "    masked_cdr3 = \"-\" * len(h_regions[5]) if h_regions[5] else \"\"\n",
    "    heavy_masked = h_regions[0] + h_regions[1] + h_regions[2] + h_regions[3] + h_regions[4] + masked_cdr3 + h_regions[6]\n",
    "    light_seq_full = \"\".join(l_regions) if l_regions else \"\"\n",
    "\n",
    "    return [('H', heavy_masked), ('L', light_seq_full)]\n",
    "\n",
    "\n",
    "def get_epitope(pdb_path, receptor_chains, ligand_chains, out_path, k=48):\n",
    "    epitope, _ = get_interface(pdb=pdb_path, receptor_chains=receptor_chains,\n",
    "                               ligand_chains=ligand_chains, num_epitope_residues=k)\n",
    "    data = []\n",
    "    for res, chain_name, _ in epitope:\n",
    "        data.append((chain_name, res.get_id()))\n",
    "    with open(out_path, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "\n",
    "# === Config ===\n",
    "pdb_dir = \"/spinning1/sharedby/hz362/AbFlow/data/rabd/pdb\"\n",
    "output_dir = \"./dymean_results\"\n",
    "ckpt_path = \"/spinning1/sharedby/hz362/AbFlow/benchmarks/dyMEAN/checkpoints/cdrh3_design.ckpt\"\n",
    "gpu_id = 0\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# === Loop through PDBs and design HCDR3 ===\n",
    "for pdb_file in Path(pdb_dir).glob(\"*.pdb\"):\n",
    "    pdb_id = pdb_file.stem\n",
    "    print(f\"Designing HCDR3 for: {pdb_id}\")\n",
    "\n",
    "    # try:\n",
    "    heavy_chain, light_chain, antigen_chain = extract_chains_from_filename(pdb_file)\n",
    "\n",
    "    epitope_path = os.path.join(output_dir, f\"{pdb_id}_epitope.json\")\n",
    "    out_pdb_dir = os.path.join(output_dir, pdb_id)\n",
    "    os.makedirs(out_pdb_dir, exist_ok=True)\n",
    "\n",
    "    get_epitope(str(pdb_file),\n",
    "                receptor_chains=[antigen_chain],\n",
    "                ligand_chains=[heavy_chain],\n",
    "                out_path=epitope_path)\n",
    "\n",
    "    heavy_seq, light_seq = extract_sequences(str(pdb_file), heavy_chain, light_chain)\n",
    "    frameworks = [get_frameworks(heavy_seq, light_seq)]\n",
    "\n",
    "    design(\n",
    "        ckpt=ckpt_path,\n",
    "        gpu=gpu_id,\n",
    "        pdbs=[str(pdb_file)],\n",
    "        epitope_defs=[epitope_path],\n",
    "        frameworks=frameworks,\n",
    "        out_dir=out_pdb_dir,\n",
    "        identifiers=[pdb_id],\n",
    "        remove_chains=[[heavy_chain]],\n",
    "        enable_openmm_relax=False,\n",
    "        auto_detect_cdrs=False\n",
    "    )\n",
    "\n",
    "    # except Exception as e:\n",
    "    #     print(f\"‚ùå Failed to process {pdb_id}: {e}\")\n",
    "    #     continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Source folder containing all the result subfolders\n",
    "src_dir = Path(\"/spinning1/sharedby/hz362/AbFlow/scripts/analysis/dymean_results\")\n",
    "# Target folder to collect cleaned PDBs\n",
    "target_dir = src_dir.parent / \"dymean\"\n",
    "target_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for subdir in src_dir.iterdir():\n",
    "    if subdir.is_dir():\n",
    "        pdb_name = f\"{subdir.name}.pdb\"\n",
    "        pdb_path = subdir / pdb_name\n",
    "\n",
    "        if pdb_path.exists():\n",
    "            dst_path = target_dir / pdb_name\n",
    "            shutil.copy(pdb_path, dst_path)\n",
    "            print(f\"‚úÖ Copied {pdb_name} to {target_dir}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Missing PDB: {pdb_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RosettaAb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# === PATHS === \n",
    "rosetta_bin = \"/spinning1/sharedby/hz362/AbFlow/benchmarks/rosetta/source/bin/antibody_designer.default.linuxgccrelease\"\n",
    "input_folder = \"/spinning1/sharedby/hz362/AbFlow/data/rabd/pdb\"\n",
    "output_root = \"/spinning1/sharedby/hz362/AbFlow/benchmarks/rosetta/output\"\n",
    "nstruct = 1\n",
    "\n",
    "# === Ensure output folder exists ===\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "# === Batch process PDBs ===\n",
    "for pdb_file in Path(input_folder).glob(\"*.pdb\"):\n",
    "    pdb_id = pdb_file.stem\n",
    "    outdir = Path(output_root) / pdb_id\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    command = [\n",
    "        rosetta_bin,\n",
    "        \"-s\", str(pdb_file),\n",
    "        \"-primary_cdrs\", \"H3\",\n",
    "        \"-graft_design_cdrs\", \"H3\",\n",
    "        \"-seq_design_cdrs\", \"H3\",\n",
    "        \"-light_chain\", \"kappa\",\n",
    "        \"-nstruct\", str(nstruct),\n",
    "        \"-out:path:all\", str(outdir),\n",
    "        \"-mintype\", \"min\",\n",
    "        \"-mc_optimize_dG\",\n",
    "        \"-disallow_aa\", \"PRO\", \"CYS\"\n",
    "    ]\n",
    "\n",
    "    print(f\"Running RAbD on {pdb_file.name}...\")\n",
    "    subprocess.run(command)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
